#!/usr/bin/env python3
"""
SupervisionåŠŸèƒ½æ¼”ç¤ºè„šæœ¬
å±•ç¤ºç›®æ ‡è·Ÿè¸ªã€è®¡æ•°å’Œå¯è§†åŒ–åŠŸèƒ½
"""

import cv2
import supervision as sv
from ultralytics import YOLO
from pathlib import Path
import numpy as np

def demo_object_tracking():
    """ç›®æ ‡è·Ÿè¸ªæ¼”ç¤º"""
    print("ğŸ¯ ç›®æ ‡è·Ÿè¸ªæ¼”ç¤º")
    
    # åˆ›å»ºè§†é¢‘ä¿¡æ¯
    video_info = sv.VideoInfo.from_video_path("test_video.mp4") if Path("test_video.mp4").exists() else None
    
    if video_info is None:
        print("   âš ï¸ æœªæ‰¾åˆ°æµ‹è¯•è§†é¢‘ï¼Œä½¿ç”¨å›¾åƒæ¼”ç¤º")
        # ä½¿ç”¨å›¾åƒæ¼”ç¤º
        if not Path("sample_image.jpg").exists():
            # åˆ›å»ºç¤ºä¾‹å›¾åƒ
            img = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)
            cv2.imwrite("sample_image.jpg", img)
        
        # åŠ è½½æ¨¡å‹
        model = YOLO("yolov8s.pt")
        
        # è¯»å–å›¾åƒ
        image = cv2.imread("sample_image.jpg")
        
        # æ£€æµ‹
        results = model(image)[0]
        detections = sv.Detections.from_ultralytics(results)
        
        # åˆå§‹åŒ–è·Ÿè¸ªå™¨
        byte_tracker = sv.ByteTrack()
        
        # è·Ÿè¸ª
        tracked_detections = byte_tracker.update_with_detections(detections)
        
        print(f"   æ£€æµ‹åˆ° {len(detections)} ä¸ªç›®æ ‡")
        print(f"   è·Ÿè¸ªåˆ° {len(tracked_detections)} ä¸ªç›®æ ‡")
        
        # å¯è§†åŒ–
        box_annotator = sv.BoxAnnotator()
        annotated_frame = box_annotator.annotate(
            scene=image.copy(), 
            detections=tracked_detections
        )
        
        label_annotator = sv.LabelAnnotator()
        labels = [
            f"#{tracker_id}"
            for tracker_id in tracked_detections.tracker_id
        ]
        annotated_frame = label_annotator.annotate(
            scene=annotated_frame, 
            detections=tracked_detections, 
            labels=labels
        )
        
        cv2.imwrite("tracked_image.jpg", annotated_frame)
        print("   è·Ÿè¸ªç»“æœä¿å­˜ä¸º tracked_image.jpg")
    else:
        print("   ä½¿ç”¨è§†é¢‘è¿›è¡Œè·Ÿè¸ªæ¼”ç¤º")
        # è§†é¢‘è·Ÿè¸ªå®ç°...

def demo_object_counting():
    """ç›®æ ‡è®¡æ•°æ¼”ç¤º"""
    print("\nğŸ”¢ ç›®æ ‡è®¡æ•°æ¼”ç¤º")
    
    # åˆ›å»ºå¤šè¾¹å½¢åŒºåŸŸç”¨äºè®¡æ•°
    polygon = np.array([
        [0, 0],
        [640, 0],
        [640, 480],
        [0, 480]
    ])
    
    # åˆ›å»ºåŒºåŸŸ
    polygon_zone = sv.PolygonZone(
        polygon=polygon
    )
    
    # åˆ›å»ºåŒºåŸŸæ³¨é‡Šå™¨
    zone_annotator = sv.PolygonZoneAnnotator(
        zone=polygon_zone,
        color=sv.Color.RED,
        thickness=2,
        text_thickness=4,
        text_scale=2
    )
    
    # æ¨¡æ‹Ÿæ£€æµ‹ç»“æœ
    # åœ¨å®é™…åº”ç”¨ä¸­ï¼Œè¿™äº›å°†æ¥è‡ªYOLOæ¨¡å‹
    detections = sv.Detections(
        xyxy=np.array([
            [100, 100, 200, 200],
            [300, 300, 400, 400],
            [500, 100, 600, 200]
        ]),
        class_id=np.array([0, 1, 2]),
        confidence=np.array([0.9, 0.8, 0.7])
    )
    
    # æ›´æ–°åŒºåŸŸè§¦å‘
    mask = polygon_zone.trigger(detections=detections)
    
    print(f"   åŒºåŸŸå†…ç›®æ ‡æ•°: {polygon_zone.current_count}")
    print(f"   æ€»è§¦å‘æ•°: {sum(mask)}")
    
    # å¯è§†åŒ–
    sample_image = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)
    annotated_frame = zone_annotator.annotate(scene=sample_image)
    
    cv2.imwrite("counted_image.jpg", annotated_frame)
    print("   è®¡æ•°ç»“æœä¿å­˜ä¸º counted_image.jpg")

def demo_visualization():
    """å¯è§†åŒ–æ¼”ç¤º"""
    print("\nğŸ¨ å¯è§†åŒ–æ¼”ç¤º")
    
    # åˆ›å»ºç¤ºä¾‹æ£€æµ‹ç»“æœ
    detections = sv.Detections(
        xyxy=np.array([
            [50, 50, 150, 150],
            [200, 100, 300, 200],
            [400, 150, 500, 250]
        ]),
        class_id=np.array([0, 1, 2]),
        confidence=np.array([0.95, 0.85, 0.75])
    )
    
    # åˆ›å»ºä¸åŒç±»å‹çš„æ³¨é‡Šå™¨
    box_annotator = sv.BoxAnnotator(
        color=sv.ColorPalette.DEFAULT,
        thickness=2
    )
    
    label_annotator = sv.LabelAnnotator(
        color=sv.ColorPalette.DEFAULT
    )
    
    # ç±»åˆ«åç§°
    class_names = ['è¡Œäºº', 'è½¦è¾†', 'è‡ªè¡Œè½¦']
    
    # åˆ›å»ºæ ‡ç­¾
    labels = [
        f"{class_names[class_id]} {confidence:.2f}"
        for class_id, confidence in zip(detections.class_id, detections.confidence)
    ]
    
    # åº”ç”¨æ³¨é‡Š
    image = np.random.randint(0, 255, (300, 600, 3), dtype=np.uint8)
    annotated_image = box_annotator.annotate(
        scene=image.copy(), 
        detections=detections
    )
    annotated_image = label_annotator.annotate(
        scene=annotated_image, 
        detections=detections, 
        labels=labels
    )
    
    cv2.imwrite("visualized_image.jpg", annotated_image)
    print("   å¯è§†åŒ–ç»“æœä¿å­˜ä¸º visualized_image.jpg")

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 50)
    print("SupervisionåŠŸèƒ½æ¼”ç¤º")
    print("=" * 50)
    
    # ç›®æ ‡è·Ÿè¸ª
    demo_object_tracking()
    
    # ç›®æ ‡è®¡æ•°
    demo_object_counting()
    
    # å¯è§†åŒ–
    demo_visualization()
    
    print("\nâœ… æ‰€æœ‰æ¼”ç¤ºå®Œæˆ!")

if __name__ == "__main__":
    main()