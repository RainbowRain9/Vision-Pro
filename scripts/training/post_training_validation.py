#!/usr/bin/env python3
"""
è®­ç»ƒå®Œæˆåçš„è‡ªåŠ¨éªŒè¯è„šæœ¬
ä½¿ç”¨supervisionè¿›è¡Œæ¨¡å‹éªŒè¯å’Œè¯„ä¼°
"""

import os
import cv2
import numpy as np
from pathlib import Path
from ultralytics import YOLO
import supervision as sv

def validate_model(model_path, data_yaml):
    """éªŒè¯è®­ç»ƒå¥½çš„æ¨¡å‹"""
    print("ğŸ” éªŒè¯è®­ç»ƒå¥½çš„æ¨¡å‹...")
    
    # åŠ è½½æ¨¡å‹
    if not Path(model_path).exists():
        print(f"   âš ï¸ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        return
    
    model = YOLO(model_path)
    print(f"   ğŸ¤– åŠ è½½æ¨¡å‹: {model_path}")
    
    # åŠ è½½æ•°æ®é›†ä¿¡æ¯
    import yaml
    with open(data_yaml, 'r') as f:
        dataset_info = yaml.safe_load(f)
    
    class_names = dataset_info['names']
    print(f"   ğŸ“Š æ•°æ®é›†ç±»åˆ«: {len(class_names)}")
    
    # éªŒè¯é›†è·¯å¾„
    val_images = Path(data_yaml).parent / "images" / "val"
    val_labels = Path(data_yaml).parent / "labels" / "val"
    
    if not val_images.exists():
        print("   âš ï¸ éªŒè¯é›†å›¾åƒç›®å½•ä¸å­˜åœ¨")
        return
    
    # åˆå§‹åŒ–æŒ‡æ ‡
    total_gt = 0
    total_tp = 0
    total_images = 0
    
    # éå†éªŒè¯é›†ï¼ˆå‰20å¼ å›¾åƒï¼‰
    val_files = list(val_images.glob("*.jpg"))[:20]
    
    print(f"   ğŸ“· å¤„ç†éªŒè¯å›¾åƒ: {len(val_files)} å¼ ")
    
    for img_file in val_files:
        # è¯»å–å›¾åƒ
        image = cv2.imread(str(img_file))
        if image is None:
            continue
            
        h, w = image.shape[:2]
        total_images += 1
        
        # YOLOæ¨ç†
        results = model(image, verbose=False)[0]
        pred_dets = sv.Detections.from_ultralytics(results)
        
        # è¯»å–çœŸå®æ ‡æ³¨
        label_file = val_labels / f"{img_file.stem}.txt"
        if label_file.exists():
            # è¯»å–YOLOæ ¼å¼æ ‡æ³¨
            with open(label_file, 'r') as f:
                lines = f.readlines()
            
            if lines:
                # è§£ææ ‡æ³¨
                class_ids = []
                xyxy_boxes = []
                for line in lines:
                    parts = line.strip().split()
                    class_id = int(parts[0])
                    x_center, y_center, width, height = map(float, parts[1:5])
                    
                    # è½¬æ¢ä¸ºåƒç´ åæ ‡
                    x1 = (x_center - width/2) * w
                    y1 = (y_center - height/2) * h
                    x2 = (x_center + width/2) * w
                    y2 = (y_center + height/2) * h
                    
                    class_ids.append(class_id)
                    xyxy_boxes.append([x1, y1, x2, y2])
                
                # åˆ›å»ºDetectionså¯¹è±¡
                gt_dets = sv.Detections(
                    xyxy=np.array(xyxy_boxes),
                    class_id=np.array(class_ids)
                )
                
                # è®¡ç®—åŒ¹é…
                if len(gt_dets) > 0 and len(pred_dets) > 0:
                    # è®¡ç®—IoUçŸ©é˜µ
                    from supervision.metrics.detection import box_iou_batch
                    iou_matrix = box_iou_batch(gt_dets.xyxy, pred_dets.xyxy)
                    # è®¡ç®—åŒ¹é…æ•°ï¼ˆIoU > 0.5ï¼‰
                    matches = (iou_matrix > 0.5).sum()
                    total_tp += matches
                
                total_gt += len(gt_dets)
    
    # è®¡ç®—å‡†ç¡®ç‡
    if total_gt > 0:
        accuracy = total_tp / total_gt if total_gt > 0 else 0
        print(f"\nğŸ“Š éªŒè¯ç»“æœ:")
        print(f"   å¤„ç†å›¾åƒæ•°: {total_images}")
        print(f"   æ€»çœŸå®æ¡†æ•°: {total_gt}")
        print(f"   æ­£ç¡®æ£€æµ‹æ•°: {total_tp}")
        print(f"   å‡†ç¡®ç‡ (IoU=0.5): {accuracy:.2%}")
    else:
        print("   âš ï¸ æ— æ ‡æ³¨æ•°æ®ç”¨äºéªŒè¯")

def generate_predictions_visualization(model_path, data_yaml):
    """ç”Ÿæˆé¢„æµ‹ç»“æœå¯è§†åŒ–"""
    print("\nğŸ¨ ç”Ÿæˆé¢„æµ‹ç»“æœå¯è§†åŒ–...")
    
    # åŠ è½½æ¨¡å‹
    if not Path(model_path).exists():
        print(f"   âš ï¸ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        return
    
    model = YOLO(model_path)
    
    # åŠ è½½æ•°æ®é›†ä¿¡æ¯
    import yaml
    with open(data_yaml, 'r') as f:
        dataset_info = yaml.safe_load(f)
    
    class_names = dataset_info['names']
    
    # éªŒè¯é›†è·¯å¾„
    val_images = Path(data_yaml).parent / "images" / "val"
    
    if not val_images.exists():
        print("   âš ï¸ éªŒè¯é›†å›¾åƒç›®å½•ä¸å­˜åœ¨")
        return
    
    # åˆ›å»ºå¯è§†åŒ–ç›®å½•
    vis_dir = Path("predictions_visualization")
    vis_dir.mkdir(exist_ok=True)
    
    # é€‰æ‹©å‡ å¼ å›¾åƒè¿›è¡Œå¯è§†åŒ–
    image_files = list(val_images.glob("*.jpg"))[:5]
    
    # åˆ›å»ºæ³¨é‡Šå™¨
    box_annotator = sv.BoxAnnotator(thickness=2)
    label_annotator = sv.LabelAnnotator()
    
    for img_file in image_files:
        # è¯»å–å›¾åƒ
        image = cv2.imread(str(img_file))
        if image is None:
            continue
        
        # YOLOæ¨ç†
        results = model(image, verbose=False)[0]
        detections = sv.Detections.from_ultralytics(results)
        
        # æ³¨é‡Šå›¾åƒ
        annotated_image = box_annotator.annotate(scene=image, detections=detections)
        
        # æ·»åŠ æ ‡ç­¾
        if len(detections) > 0:
            labels = [
                f"{class_names[class_id]} {confidence:.2f}"
                for class_id, confidence in zip(detections.class_id, detections.confidence)
            ]
            annotated_image = label_annotator.annotate(
                scene=annotated_image, 
                detections=detections, 
                labels=labels
            )
        
        # ä¿å­˜å¯è§†åŒ–ç»“æœ
        output_file = vis_dir / f"pred_{img_file.name}"
        cv2.imwrite(str(output_file), annotated_image)
    
    print(f"   é¢„æµ‹å¯è§†åŒ–ä¿å­˜åˆ°: {vis_dir}")

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 50)
    print("æ¨¡å‹éªŒè¯å’Œè¯„ä¼°")
    print("=" * 50)
    
    # æ¨¡å‹è·¯å¾„å’Œæ•°æ®é…ç½®
    model_path = "runs/train_enhanced/20250902_203931/weights/best.pt"
    data_yaml = "data/visdrone_yolo/data.yaml"
    
    # éªŒè¯æ¨¡å‹
    validate_model(model_path, data_yaml)
    
    # ç”Ÿæˆé¢„æµ‹å¯è§†åŒ–
    generate_predictions_visualization(model_path, data_yaml)
    
    print("\nâœ… éªŒè¯å®Œæˆ!")

if __name__ == "__main__":
    main()