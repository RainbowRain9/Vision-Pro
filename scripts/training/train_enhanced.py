#!/usr/bin/env python3
"""
å¢å¼ºç‰ˆYOLOv8è®­ç»ƒè„šæœ¬
é›†æˆsupervisionè¿›è¡Œè®­ç»ƒç›‘æ§å’Œå¢å¼º
"""

import os
import sys
import torch
from pathlib import Path
from datetime import datetime

# å¯¼å…¥å¿…è¦çš„åº“
from ultralytics import YOLO
import supervision as sv
import numpy as np
import cv2

# è®¾ç½®é¡¹ç›®æ ¹ç›®å½•
ROOT = Path(__file__).parent
sys.path.insert(0, str(ROOT))

class EnhancedYOLOTrainer:
    """å¢å¼ºç‰ˆYOLOè®­ç»ƒå™¨ï¼Œé›†æˆsupervisionåŠŸèƒ½"""
    
    def __init__(self, model_path="yolov8s.pt", data_yaml="data/visdrone_yolo/data.yaml"):
        """
        åˆå§‹åŒ–è®­ç»ƒå™¨
        
        Args:
            model_path: é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„æˆ–é…ç½®æ–‡ä»¶
            data_yaml: æ•°æ®é›†é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.model_path = model_path
        self.data_yaml = data_yaml
        self.model = None
        self.dataset_info = None
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        self.output_dir = ROOT / "runs" / "train_enhanced" / datetime.now().strftime("%Y%m%d_%H%M%S")
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
    def setup(self):
        """è®¾ç½®è®­ç»ƒç¯å¢ƒ"""
        print("=" * 60)
        print("å¢å¼ºç‰ˆYOLOv8è®­ç»ƒ - é›†æˆSupervision")
        print("=" * 60)
        
        # æ£€æŸ¥GPU
        if torch.cuda.is_available():
            print(f"âœ… ä½¿ç”¨GPU: {torch.cuda.get_device_name(0)}")
            print(f"   æ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")
            self.device = 0
        else:
            print("âš ï¸ GPUä¸å¯ç”¨ï¼Œä½¿ç”¨CPUè®­ç»ƒ")
            self.device = 'cpu'
            
        # åŠ è½½æ•°æ®é›†ä¿¡æ¯
        import yaml
        with open(self.data_yaml, 'r') as f:
            self.dataset_info = yaml.safe_load(f)
        print(f"\nğŸ“Š æ•°æ®é›†: {self.data_yaml}")
        print(f"   ç±»åˆ«æ•°: {len(self.dataset_info['names'])}")
        print(f"   ç±»åˆ«: {', '.join(self.dataset_info['names'])}")
        
        # åˆå§‹åŒ–æ¨¡å‹
        print(f"\nğŸ¤– åŠ è½½æ¨¡å‹: {self.model_path}")
        
        # åˆ¤æ–­æ˜¯é…ç½®æ–‡ä»¶è¿˜æ˜¯æƒé‡æ–‡ä»¶
        if str(self.model_path).endswith('.yaml'):
            # ä»é…ç½®æ–‡ä»¶åˆ›å»ºæ–°æ¨¡å‹
            self.model = YOLO(self.model_path)
            # åŠ è½½é¢„è®­ç»ƒæƒé‡
            if Path("models/yolov8s.pt").exists():
                print("   åŠ è½½é¢„è®­ç»ƒæƒé‡: models/yolov8s.pt")
                self.model.load("models/yolov8s.pt")
        else:
            # ç›´æ¥åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
            self.model = YOLO(self.model_path)
            
    def analyze_dataset(self):
        """ä½¿ç”¨supervisionåˆ†ææ•°æ®é›†"""
        print("\nğŸ“ˆ æ•°æ®é›†åˆ†æ...")
        
        # è¯»å–è®­ç»ƒé›†å›¾åƒ
        train_images = Path(self.data_yaml).parent / "images" / "train"
        train_labels = Path(self.data_yaml).parent / "labels" / "train"
        
        if not train_images.exists():
            print("âš ï¸ è®­ç»ƒé›†ä¸å­˜åœ¨")
            return
            
        # ç»Ÿè®¡ä¿¡æ¯
        image_files = list(train_images.glob("*.jpg"))
        print(f"   è®­ç»ƒå›¾åƒæ•°: {len(image_files)}")
        
        # åˆ†ææ ‡æ³¨åˆ†å¸ƒ
        class_counts = {name: 0 for name in self.dataset_info['names']}
        total_boxes = 0
        
        for img_file in image_files[:100]:  # åˆ†æå‰100å¼ 
            label_file = train_labels / f"{img_file.stem}.txt"
            if label_file.exists():
                with open(label_file, 'r') as f:
                    lines = f.readlines()
                    total_boxes += len(lines)
                    for line in lines:
                        class_id = int(line.split()[0])
                        class_name = self.dataset_info['names'][class_id]
                        class_counts[class_name] += 1
                        
        print(f"   æ€»æ ‡æ³¨æ¡†æ•°: {total_boxes}")
        print("\n   ç±»åˆ«åˆ†å¸ƒ (å‰100å¼ ):")
        for name, count in sorted(class_counts.items(), key=lambda x: x[1], reverse=True):
            if count > 0:
                print(f"      {name}: {count}")
                
    def train(self, epochs=100, imgsz=640, batch=16):
        """
        è®­ç»ƒæ¨¡å‹
        
        Args:
            epochs: è®­ç»ƒè½®æ•°
            imgsz: è¾“å…¥å›¾åƒå°ºå¯¸
            batch: æ‰¹æ¬¡å¤§å°
        """
        print(f"\nğŸš€ å¼€å§‹è®­ç»ƒ")
        print(f"   è½®æ•°: {epochs}")
        print(f"   å›¾åƒå°ºå¯¸: {imgsz}")
        print(f"   æ‰¹æ¬¡å¤§å°: {batch}")
        print(f"   è¾“å‡ºç›®å½•: {self.output_dir}")
        
        # è®­ç»ƒå‚æ•°
        train_args = {
            'data': self.data_yaml,
            'epochs': epochs,
            'imgsz': imgsz,
            'batch': batch,
            'device': self.device,
            'project': str(self.output_dir.parent),
            'name': self.output_dir.name,
            'exist_ok': True,
            'patience': 20,  # æ—©åœ
            'save_period': 10,  # æ¯10è½®ä¿å­˜
            'workers': 4,
            'amp': True if self.device != 'cpu' else False,  # æ··åˆç²¾åº¦è®­ç»ƒ
            'cache': False,  # ç¼“å­˜å›¾åƒåˆ°å†…å­˜
            'verbose': True,
            'plots': True,  # ç”Ÿæˆè®­ç»ƒå›¾è¡¨
        }
        
        # å¼€å§‹è®­ç»ƒ
        results = self.model.train(**train_args)
        
        print("\nâœ… è®­ç»ƒå®Œæˆ!")
        print(f"   æœ€ä½³æ¨¡å‹: {self.output_dir}/weights/best.pt")
        
        return results
        
    def validate_with_supervision(self):
        """ä½¿ç”¨supervisionè¿›è¡ŒéªŒè¯"""
        print("\nğŸ” ä½¿ç”¨Supervisionè¿›è¡ŒéªŒè¯...")
        
        # åŠ è½½æœ€ä½³æ¨¡å‹
        best_model_path = self.output_dir / "weights" / "best.pt"
        if not best_model_path.exists():
            print("âš ï¸ æœªæ‰¾åˆ°è®­ç»ƒå¥½çš„æ¨¡å‹")
            return
            
        model = YOLO(best_model_path)
        
        # éªŒè¯é›†è·¯å¾„
        val_images = Path(self.data_yaml).parent / "images" / "val"
        val_labels = Path(self.data_yaml).parent / "labels" / "val"
        
        # åˆå§‹åŒ–æŒ‡æ ‡
        total_gt = 0
        total_tp = 0
        class_names = self.dataset_info['names']
        
        # éå†éªŒè¯é›†
        val_files = list(val_images.glob("*.jpg"))[:50]  # éªŒè¯å‰50å¼ 
        
        for img_file in val_files:
            # è¯»å–å›¾åƒ
            img = cv2.imread(str(img_file))
            h, w = img.shape[:2]
            
            # YOLOæ¨ç†
            results = model(img, verbose=False)[0]
            pred_dets = sv.Detections.from_ultralytics(results)
            
            # è¯»å–çœŸå®æ ‡æ³¨
            label_file = val_labels / f"{img_file.stem}.txt"
            if label_file.exists():
                # ä½¿ç”¨æ–°çš„supervision API
                import numpy as np
                # è¯»å–YOLOæ ¼å¼æ ‡æ³¨
                with open(label_file, 'r') as f:
                    lines = f.readlines()
                
                if lines:
                    # è§£ææ ‡æ³¨
                    class_ids = []
                    xyxy_boxes = []
                    for line in lines:
                        parts = line.strip().split()
                        class_id = int(parts[0])
                        x_center, y_center, width, height = map(float, parts[1:5])
                        
                        # è½¬æ¢ä¸ºåƒç´ åæ ‡
                        x1 = (x_center - width/2) * w
                        y1 = (y_center - height/2) * h
                        x2 = (x_center + width/2) * w
                        y2 = (y_center + height/2) * h
                        
                        class_ids.append(class_id)
                        xyxy_boxes.append([x1, y1, x2, y2])
                    
                    # åˆ›å»ºDetectionså¯¹è±¡
                    gt_dets = sv.Detections(
                        xyxy=np.array(xyxy_boxes),
                        class_id=np.array(class_ids)
                    )
                else:
                    # ç©ºæ ‡æ³¨
                    gt_dets = sv.Detections(
                        xyxy=np.empty((0, 4)),
                        class_id=np.empty(0)
                    )
                
                # ä½¿ç”¨æ–°çš„åŒ¹é…å‡½æ•°
                try:
                    matches = sv.metrics.detection.match_detections(
                        gt_dets, pred_dets, iou_threshold=0.5
                    )
                    # ç¡®ä¿matchesæ˜¯ä¸€ä¸ªæ•°ç»„æˆ–åˆ—è¡¨
                    if isinstance(matches, (int, np.integer)):
                        matches = [matches] if matches > 0 else []
                except:
                    # å¦‚æœæ²¡æœ‰åŒ¹é…å‡½æ•°ï¼Œæ‰‹åŠ¨è®¡ç®—IoUåŒ¹é…
                    matches = []
                    if len(gt_dets) > 0 and len(pred_dets) > 0:
                        from supervision.metrics.detection import box_iou_batch
                        iou_matrix = box_iou_batch(gt_dets.xyxy, pred_dets.xyxy)
                        matched_indices = (iou_matrix > 0.5).sum()
                        matches = [1] * matched_indices  # åˆ›å»ºä¸€ä¸ªåŒ…å«åŒ¹é…æ•°çš„åˆ—è¡¨
                
                total_gt += len(gt_dets)
                total_tp += len(matches)
                
        # è®¡ç®—å‡†ç¡®ç‡
        if total_gt > 0:
            accuracy = total_tp / total_gt
            print(f"\nğŸ“Š éªŒè¯ç»“æœ (å‰50å¼ ):")
            print(f"   æ€»çœŸå®æ¡†æ•°: {total_gt}")
            print(f"   æ­£ç¡®æ£€æµ‹æ•°: {total_tp}")
            print(f"   å‡†ç¡®ç‡ (IoU=0.5): {accuracy:.2%}")
        else:
            print("âš ï¸ éªŒè¯é›†æ— æ ‡æ³¨")
            
    def export_model(self, format='onnx'):
        """å¯¼å‡ºæ¨¡å‹"""
        print(f"\nğŸ“¦ å¯¼å‡ºæ¨¡å‹ä¸º {format.upper()} æ ¼å¼...")
        
        best_model_path = self.output_dir / "weights" / "best.pt"
        if not best_model_path.exists():
            print("âš ï¸ æœªæ‰¾åˆ°è®­ç»ƒå¥½çš„æ¨¡å‹")
            return
            
        model = YOLO(best_model_path)
        export_path = model.export(format=format, dynamic=True)
        print(f"   å¯¼å‡ºæˆåŠŸ: {export_path}")
        
        return export_path


def main():
    """ä¸»å‡½æ•°"""
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = EnhancedYOLOTrainer(
        model_path="yolov8s.pt",  # ä½¿ç”¨YOLOv8sé¢„è®­ç»ƒæ¨¡å‹
        data_yaml="data/visdrone_yolo/data.yaml"
    )
    
    # è®¾ç½®ç¯å¢ƒ
    trainer.setup()
    
    # åˆ†ææ•°æ®é›†
    trainer.analyze_dataset()
    
    # ä½¿ç”¨GPUè®­ç»ƒå‚æ•°
    epochs = 30  # GPUè®­ç»ƒ30è½®
    imgsz = 640
    batch = 16
    
    # å¼€å§‹è®­ç»ƒ
    trainer.train(epochs=epochs, imgsz=imgsz, batch=batch)
    
    # ä½¿ç”¨supervisionéªŒè¯
    trainer.validate_with_supervision()
    
    # å¯¼å‡ºæ¨¡å‹
    # trainer.export_model('onnx')
    
    print("\nğŸ‰ æ‰€æœ‰ä»»åŠ¡å®Œæˆ!")


if __name__ == "__main__":
    main()