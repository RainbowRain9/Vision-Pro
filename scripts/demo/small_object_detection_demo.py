#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
å°ç›®æ ‡æ£€æµ‹æ¼”ç¤ºè„šæœ¬
å±•ç¤ºå¦‚ä½•ä½¿ç”¨ InferenceSlicer è¿›è¡Œå°ç›®æ ‡æ£€æµ‹
"""

import os
import sys
import cv2
import numpy as np
import time
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
current_dir = Path(__file__).parent
project_root = current_dir.parent.parent
sys.path.insert(0, str(project_root))

# æ·»åŠ  ultralytics è·¯å¾„
ultralytics_path = project_root / "ultralytics"
if ultralytics_path.exists():
    sys.path.insert(0, str(ultralytics_path))

from ultralytics import YOLO
from scripts.modules.supervision_wrapper import SupervisionWrapper


def load_model(model_path: str = None):
    """åŠ è½½ YOLO æ¨¡å‹"""
    if model_path is None:
        # ä½¿ç”¨é¡¹ç›®ä¸­çš„æ¨¡å‹
        models_dir = project_root / "models"
        model_files = list(models_dir.glob("*.pt"))
        if model_files:
            model_path = str(model_files[0])
        else:
            model_path = "yolov8s.pt"  # é»˜è®¤æ¨¡å‹
    
    print(f"ğŸ”„ åŠ è½½æ¨¡å‹: {model_path}")
    model = YOLO(model_path)
    print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
    return model


def demo_basic_detection(image_path: str, model):
    """æ¼”ç¤ºåŸºç¡€æ£€æµ‹"""
    print("\n" + "="*50)
    print("ğŸ“¸ åŸºç¡€æ£€æµ‹æ¼”ç¤º")
    print("="*50)
    
    # è¯»å–å›¾åƒ
    image = cv2.imread(image_path)
    if image is None:
        print(f"âŒ æ— æ³•è¯»å–å›¾åƒ: {image_path}")
        return None
    
    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    print(f"ğŸ“ å›¾åƒå°ºå¯¸: {image_rgb.shape}")
    
    # åŸºç¡€æ£€æµ‹
    start_time = time.time()
    results = model.predict(image_rgb, conf=0.25, iou=0.45, verbose=False)
    processing_time = time.time() - start_time
    
    # æ˜¾ç¤ºç»“æœ
    result_img = results[0].plot()
    detection_count = len(results[0].boxes) if results[0].boxes is not None else 0
    
    print(f"ğŸ¯ æ£€æµ‹ç»“æœ: {detection_count} ä¸ªç›®æ ‡")
    print(f"â±ï¸  å¤„ç†æ—¶é—´: {processing_time:.2f}s")
    
    return result_img, detection_count, processing_time


def demo_small_object_detection(image_path: str, model):
    """æ¼”ç¤ºå°ç›®æ ‡æ£€æµ‹"""
    print("\n" + "="*50)
    print("ğŸ” å°ç›®æ ‡æ£€æµ‹æ¼”ç¤º (InferenceSlicer)")
    print("="*50)
    
    # è¯»å–å›¾åƒ
    image = cv2.imread(image_path)
    if image is None:
        print(f"âŒ æ— æ³•è¯»å–å›¾åƒ: {image_path}")
        return None
    
    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    # åˆå§‹åŒ– Supervision åŒ…è£…å™¨
    class_names = [
        'pedestrian', 'people', 'bicycle', 'car', 'van',
        'truck', 'tricycle', 'awning-tricycle', 'bus', 'motor'
    ]
    wrapper = SupervisionWrapper(class_names=class_names)
    
    # å°ç›®æ ‡æ£€æµ‹
    print("ğŸ”„ æ‰§è¡Œå°ç›®æ ‡æ£€æµ‹...")
    result = wrapper.detect_small_objects(
        image_rgb, model, 
        conf=0.25, iou=0.45,
        slice_wh=(640, 640),
        overlap_wh=(128, 128)
    )
    
    if 'error' in result:
        print(f"âŒ æ£€æµ‹å¤±è´¥: {result['error']}")
        return None
    
    # æ˜¾ç¤ºç»“æœ
    detection_count = result['detection_count']
    processing_time = result['statistics'].get('processing_time', 0)
    slice_config = result['statistics'].get('slice_config', {})
    total_slices = slice_config.get('total_slices', 0)
    
    print(f"ğŸ¯ æ£€æµ‹ç»“æœ: {detection_count} ä¸ªç›®æ ‡")
    print(f"ğŸ“Š å¤„ç†åˆ‡ç‰‡: {total_slices} ä¸ª")
    print(f"â±ï¸  å¤„ç†æ—¶é—´: {processing_time:.2f}s")
    
    # æ˜¾ç¤ºç±»åˆ«åˆ†å¸ƒ
    class_dist = result['statistics'].get('class_distribution', {})
    if class_dist:
        print("ğŸ“ˆ ç±»åˆ«åˆ†å¸ƒ:")
        for class_name, count in class_dist.items():
            print(f"   {class_name}: {count}")
    
    return result['annotated_image'], detection_count, processing_time


def demo_multi_scale_detection(image_path: str, model):
    """æ¼”ç¤ºå¤šå°ºåº¦æ£€æµ‹"""
    print("\n" + "="*50)
    print("ğŸ”„ å¤šå°ºåº¦æ£€æµ‹æ¼”ç¤º")
    print("="*50)
    
    # è¯»å–å›¾åƒ
    image = cv2.imread(image_path)
    if image is None:
        print(f"âŒ æ— æ³•è¯»å–å›¾åƒ: {image_path}")
        return None
    
    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    # åˆå§‹åŒ– Supervision åŒ…è£…å™¨
    class_names = [
        'pedestrian', 'people', 'bicycle', 'car', 'van',
        'truck', 'tricycle', 'awning-tricycle', 'bus', 'motor'
    ]
    wrapper = SupervisionWrapper(class_names=class_names)
    
    # å¤šå°ºåº¦æ£€æµ‹
    print("ğŸ”„ æ‰§è¡Œå¤šå°ºåº¦æ£€æµ‹...")
    result = wrapper.detect_with_multiple_scales(
        image_rgb, model, conf=0.25, iou=0.45
    )
    
    if 'error' in result:
        print(f"âŒ æ£€æµ‹å¤±è´¥: {result['error']}")
        return None
    
    # æ˜¾ç¤ºç»“æœ
    detection_count = result['detection_count']
    scale_results = result['statistics'].get('scale_results', {})
    
    print(f"ğŸ¯ æœ€ç»ˆæ£€æµ‹ç»“æœ: {detection_count} ä¸ªç›®æ ‡")
    print("ğŸ“Š å„å°ºåº¦ç»“æœ:")
    total_time = 0
    for scale_name, scale_info in scale_results.items():
        count = scale_info['detection_count']
        time_cost = scale_info['processing_time']
        config = scale_info['config']
        total_time += time_cost
        print(f"   {scale_name}: {count} ä¸ªç›®æ ‡, {time_cost:.2f}s, åˆ‡ç‰‡{config['slice_wh']}")
    
    print(f"â±ï¸  æ€»å¤„ç†æ—¶é—´: {total_time:.2f}s")
    
    return result['annotated_image'], detection_count, total_time


def save_results(results: dict, output_dir: Path):
    """ä¿å­˜æ£€æµ‹ç»“æœ"""
    output_dir.mkdir(parents=True, exist_ok=True)
    
    for method_name, (result_img, count, time_cost) in results.items():
        if result_img is not None:
            # ä¿å­˜å›¾åƒ
            output_path = output_dir / f"{method_name}_result.jpg"
            cv2.imwrite(str(output_path), cv2.cvtColor(result_img, cv2.COLOR_RGB2BGR))
            print(f"ğŸ’¾ ä¿å­˜ç»“æœ: {output_path}")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å°ç›®æ ‡æ£€æµ‹æ¼”ç¤ºç¨‹åº")
    print("="*60)
    
    # æ£€æŸ¥æµ‹è¯•å›¾åƒ
    test_images_dir = project_root / "assets" / "images"
    if not test_images_dir.exists():
        test_images_dir = project_root / "data" / "raw_images"
    
    if not test_images_dir.exists():
        print("âŒ æœªæ‰¾åˆ°æµ‹è¯•å›¾åƒç›®å½•")
        print("è¯·å°†æµ‹è¯•å›¾åƒæ”¾åœ¨ä»¥ä¸‹ç›®å½•ä¹‹ä¸€:")
        print(f"  - {project_root / 'assets' / 'images'}")
        print(f"  - {project_root / 'data' / 'raw_images'}")
        return
    
    # æŸ¥æ‰¾å›¾åƒæ–‡ä»¶
    image_files = []
    for ext in ['*.jpg', '*.jpeg', '*.png', '*.bmp']:
        image_files.extend(test_images_dir.glob(ext))
    
    if not image_files:
        print(f"âŒ åœ¨ {test_images_dir} ä¸­æœªæ‰¾åˆ°å›¾åƒæ–‡ä»¶")
        return
    
    # é€‰æ‹©ç¬¬ä¸€ä¸ªå›¾åƒè¿›è¡Œæ¼”ç¤º
    test_image = str(image_files[0])
    print(f"ğŸ“¸ ä½¿ç”¨æµ‹è¯•å›¾åƒ: {test_image}")
    
    # åŠ è½½æ¨¡å‹
    try:
        model = load_model()
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return
    
    # æ‰§è¡Œå„ç§æ£€æµ‹æ–¹æ³•
    results = {}
    
    # 1. åŸºç¡€æ£€æµ‹
    basic_result = demo_basic_detection(test_image, model)
    if basic_result:
        results['basic'] = basic_result
    
    # 2. å°ç›®æ ‡æ£€æµ‹
    small_obj_result = demo_small_object_detection(test_image, model)
    if small_obj_result:
        results['small_object'] = small_obj_result
    
    # 3. å¤šå°ºåº¦æ£€æµ‹
    multi_scale_result = demo_multi_scale_detection(test_image, model)
    if multi_scale_result:
        results['multi_scale'] = multi_scale_result
    
    # ä¿å­˜ç»“æœ
    output_dir = project_root / "results" / "small_object_demo"
    save_results(results, output_dir)
    
    # æ€§èƒ½å¯¹æ¯”
    print("\n" + "="*50)
    print("ğŸ“Š æ€§èƒ½å¯¹æ¯”æ€»ç»“")
    print("="*50)
    
    for method_name, (_, count, time_cost) in results.items():
        method_display = {
            'basic': 'åŸºç¡€æ£€æµ‹',
            'small_object': 'å°ç›®æ ‡æ£€æµ‹',
            'multi_scale': 'å¤šå°ºåº¦æ£€æµ‹'
        }.get(method_name, method_name)
        
        print(f"{method_display:12s}: {count:3d} ä¸ªç›®æ ‡, {time_cost:6.2f}s")
    
    print("\nâœ… æ¼”ç¤ºå®Œæˆï¼")
    print(f"ğŸ“ ç»“æœå·²ä¿å­˜åˆ°: {output_dir}")


if __name__ == "__main__":
    main()
