#!/usr/bin/env python3
"""
è®­ç»ƒç»“æœå¯è§†åŒ–åˆ†æè„šæœ¬
ç”¨äºåˆ†æYOLOv8è®­ç»ƒè¿‡ç¨‹å’Œç»“æœ
"""

import os
import cv2
import matplotlib.pyplot as plt
import numpy as np
from pathlib import Path
import json

def analyze_training_logs(log_dir):
    """åˆ†æè®­ç»ƒæ—¥å¿—"""
    print("ğŸ“Š åˆ†æè®­ç»ƒæ—¥å¿—...")
    
    # æŸ¥æ‰¾è®­ç»ƒæ—¥å¿—æ–‡ä»¶
    log_files = list(Path(log_dir).glob("results*.csv"))
    if not log_files:
        print("   âš ï¸ æœªæ‰¾åˆ°è®­ç»ƒæ—¥å¿—æ–‡ä»¶")
        return
    
    log_file = log_files[0]
    print(f"   æ‰¾åˆ°æ—¥å¿—æ–‡ä»¶: {log_file.name}")
    
    # è¯»å–æ—¥å¿—æ•°æ®
    import pandas as pd
    df = pd.read_csv(log_file)
    
    # ç»˜åˆ¶æŸå¤±æ›²çº¿
    plt.figure(figsize=(15, 10))
    
    # æŸå¤±æ›²çº¿
    plt.subplot(2, 3, 1)
    plt.plot(df['epoch'], df['train/box_loss'], label='Train Box Loss')
    plt.plot(df['epoch'], df['val/box_loss'], label='Val Box Loss')
    plt.title('Box Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(True)
    
    # åˆ†ç±»æŸå¤±
    plt.subplot(2, 3, 2)
    plt.plot(df['epoch'], df['train/cls_loss'], label='Train Class Loss')
    plt.plot(df['epoch'], df['val/cls_loss'], label='Val Class Loss')
    plt.title('Classification Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(True)
    
    # DFLæŸå¤±
    plt.subplot(2, 3, 3)
    plt.plot(df['epoch'], df['train/dfl_loss'], label='Train DFL Loss')
    plt.plot(df['epoch'], df['val/dfl_loss'], label='Val DFL Loss')
    plt.title('DFL Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(True)
    
    # mAPæ›²çº¿
    plt.subplot(2, 3, 4)
    plt.plot(df['epoch'], df['metrics/mAP50(B)'], label='mAP@0.5')
    plt.plot(df['epoch'], df['metrics/mAP50-95(B)'], label='mAP@0.5:0.95')
    plt.title('mAP Metrics')
    plt.xlabel('Epoch')
    plt.ylabel('mAP')
    plt.legend()
    plt.grid(True)
    
    # ç²¾ç¡®åº¦å’Œå¬å›ç‡
    plt.subplot(2, 3, 5)
    plt.plot(df['epoch'], df['metrics/precision(B)'], label='Precision')
    plt.plot(df['epoch'], df['metrics/recall(B)'], label='Recall')
    plt.title('Precision and Recall')
    plt.xlabel('Epoch')
    plt.ylabel('Value')
    plt.legend()
    plt.grid(True)
    
    # F1åˆ†æ•°
    plt.subplot(2, 3, 6)
    plt.plot(df['epoch'], df['metrics/F1(B)'], label='F1 Score')
    plt.title('F1 Score')
    plt.xlabel('Epoch')
    plt.ylabel('F1')
    plt.legend()
    plt.grid(True)
    
    plt.tight_layout()
    plt.savefig('training_analysis.png', dpi=300, bbox_inches='tight')
    plt.close()
    
    print("   è®­ç»ƒåˆ†æå›¾è¡¨ä¿å­˜ä¸º: training_analysis.png")
    
    # æ‰“å°æœ€ç»ˆç»“æœ
    final_epoch = df.iloc[-1]
    print(f"\n   æœ€ç»ˆè®­ç»ƒç»“æœ (Epoch {int(final_epoch['epoch'])}):")
    print(f"      Box Loss: {final_epoch['train/box_loss']:.4f}")
    print(f"      Class Loss: {final_epoch['train/cls_loss']:.4f}")
    print(f"      DFL Loss: {final_epoch['train/dfl_loss']:.4f}")
    print(f"      mAP@0.5: {final_epoch['metrics/mAP50(B)']:.4f}")
    print(f"      mAP@0.5:0.95: {final_epoch['metrics/mAP50-95(B)']:.4f}")
    print(f"      Precision: {final_epoch['metrics/precision(B)']:.4f}")
    print(f"      Recall: {final_epoch['metrics/recall(B)']:.4f}")
    print(f"      F1 Score: {final_epoch['metrics/F1(B)']:.4f}")

def visualize_detection_results(image_dir, label_dir, class_names):
    """å¯è§†åŒ–æ£€æµ‹ç»“æœ"""
    print("\nğŸ¨ å¯è§†åŒ–æ£€æµ‹ç»“æœ...")
    
    # è·å–å›¾åƒæ–‡ä»¶
    image_files = list(Path(image_dir).glob("*.jpg"))[:10]  # åªå¤„ç†å‰10å¼ 
    if not image_files:
        print("   âš ï¸ æœªæ‰¾åˆ°å›¾åƒæ–‡ä»¶")
        return
    
    # åˆ›å»ºå¯è§†åŒ–ç›®å½•
    vis_dir = Path("detection_visualizations")
    vis_dir.mkdir(exist_ok=True)
    
    # éšæœºé€‰æ‹©å‡ å¼ å›¾åƒè¿›è¡Œå¯è§†åŒ–
    import random
    selected_files = random.sample(image_files, min(5, len(image_files)))
    
    for img_file in selected_files:
        # è¯»å–å›¾åƒ
        image = cv2.imread(str(img_file))
        h, w = image.shape[:2]
        
        # è¯»å–æ ‡ç­¾
        label_file = Path(label_dir) / f"{img_file.stem}.txt"
        if not label_file.exists():
            continue
            
        with open(label_file, 'r') as f:
            lines = f.readlines()
        
        if not lines:
            continue
            
        # ç»˜åˆ¶è¾¹ç•Œæ¡†
        for line in lines:
            parts = line.strip().split()
            class_id = int(parts[0])
            x_center, y_center, width, height = map(float, parts[1:5])
            
            # è½¬æ¢ä¸ºåƒç´ åæ ‡
            x1 = int((x_center - width/2) * w)
            y1 = int((y_center - height/2) * h)
            x2 = int((x_center + width/2) * w)
            y2 = int((y_center + height/2) * h)
            
            # ç»˜åˆ¶è¾¹ç•Œæ¡†
            color = (0, 255, 0)  # ç»¿è‰²
            cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)
            
            # æ·»åŠ æ ‡ç­¾
            class_name = class_names[class_id] if class_id < len(class_names) else f"Class {class_id}"
            cv2.putText(image, class_name, (x1, y1-10), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)
        
        # ä¿å­˜å¯è§†åŒ–ç»“æœ
        output_file = vis_dir / f"vis_{img_file.name}"
        cv2.imwrite(str(output_file), image)
    
    print(f"   æ£€æµ‹ç»“æœå¯è§†åŒ–ä¿å­˜åˆ°: {vis_dir}")

def analyze_class_distribution(label_dir, class_names):
    """åˆ†æç±»åˆ«åˆ†å¸ƒ"""
    print("\nğŸ“ˆ åˆ†æç±»åˆ«åˆ†å¸ƒ...")
    
    # ç»Ÿè®¡æ¯ä¸ªç±»åˆ«çš„å®ä¾‹æ•°
    class_counts = {name: 0 for name in class_names}
    total_boxes = 0
    
    # éå†æ‰€æœ‰æ ‡ç­¾æ–‡ä»¶
    label_files = list(Path(label_dir).glob("*.txt"))
    for label_file in label_files:
        with open(label_file, 'r') as f:
            lines = f.readlines()
        
        for line in lines:
            parts = line.strip().split()
            if len(parts) >= 5:
                class_id = int(parts[0])
                if class_id < len(class_names):
                    class_name = class_names[class_id]
                    class_counts[class_name] += 1
                    total_boxes += 1
    
    # ç»˜åˆ¶ç±»åˆ«åˆ†å¸ƒå›¾
    plt.figure(figsize=(12, 8))
    
    # æŒ‰æ•°é‡æ’åº
    sorted_classes = sorted(class_counts.items(), key=lambda x: x[1], reverse=True)
    names, counts = zip(*sorted_classes)
    
    bars = plt.bar(range(len(names)), counts, color='skyblue')
    plt.title('ç±»åˆ«åˆ†å¸ƒ')
    plt.xlabel('ç±»åˆ«')
    plt.ylabel('å®ä¾‹æ•°')
    plt.xticks(range(len(names)), names, rotation=45, ha='right')
    
    # åœ¨æŸ±çŠ¶å›¾ä¸Šæ·»åŠ æ•°å€¼
    for i, (name, count) in enumerate(sorted_classes):
        plt.text(i, count + 0.5, str(count), ha='center', va='bottom')
    
    plt.tight_layout()
    plt.savefig('class_distribution.png', dpi=300, bbox_inches='tight')
    plt.close()
    
    print("   ç±»åˆ«åˆ†å¸ƒå›¾ä¿å­˜ä¸º: class_distribution.png")
    print(f"   æ€»æ ‡æ³¨æ¡†æ•°: {total_boxes}")
    print("\n   å„ç±»åˆ«ç»Ÿè®¡:")
    for name, count in sorted_classes:
        if count > 0:
            percentage = (count / total_boxes) * 100 if total_boxes > 0 else 0
            print(f"      {name}: {count} ({percentage:.1f}%)")

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 50)
    print("è®­ç»ƒç»“æœå¯è§†åŒ–åˆ†æ")
    print("=" * 50)
    
    # ç±»åˆ«åç§°
    class_names = [
        'pedestrian', 'people', 'bicycle', 'car', 'van', 
        'truck', 'tricycle', 'awning-tricycle', 'bus', 'motor'
    ]
    
    # åˆ†æè®­ç»ƒæ—¥å¿—
    log_dir = "runs/train_enhanced/20250902_203931"
    if Path(log_dir).exists():
        analyze_training_logs(log_dir)
    else:
        print("âš ï¸ æœªæ‰¾åˆ°è®­ç»ƒæ—¥å¿—ç›®å½•")
    
    # åˆ†æç±»åˆ«åˆ†å¸ƒ
    label_dir = "data/visdrone_yolo/labels/train"
    if Path(label_dir).exists():
        analyze_class_distribution(label_dir, class_names)
    
    # å¯è§†åŒ–æ£€æµ‹ç»“æœ
    image_dir = "data/visdrone_yolo/images/train"
    if Path(image_dir).exists():
        visualize_detection_results(image_dir, label_dir, class_names)
    
    print("\nâœ… å¯è§†åŒ–åˆ†æå®Œæˆ!")

if __name__ == "__main__":
    main()